
A) Use Default prompts
B) Use Custom prompts

>> A

Verbose: False
Use models: ['llama2:7b', 'llama3.1:8b', 'deepseek-r1:8b', 'deepseek-r1:latest', 'mistral:latest', 'qwen2.5:latest', 'gemma3:4b']
Skip models: []
Prompts: ['Why is the sky blue?', 'Write a report on the financials of Microsoft']

Running benchmark on all available models
Average stats:

----------------------------------------------------
        llama2:7b
        	Prompt eval: 1145.88 t/s
        	Response: 28.42 t/s
        	Total: 29.92 t/s

        Stats:
        	Prompt tokens: 55
        	Response tokens: 1013
        	Model load time: 3.78s
        	Prompt eval time: 0.05s
        	Response time: 35.65s
        	Total time: 39.48s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        llama3.1:8b
        	Prompt eval: 629.27 t/s
        	Response: 20.02 t/s
        	Total: 20.56 t/s

        Stats:
        	Prompt tokens: 35
        	Response tokens: 1273
        	Model load time: 10.16s
        	Prompt eval time: 0.06s
        	Response time: 63.58s
        	Total time: 73.79s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        deepseek-r1:8b
        	Prompt eval: 33.91 t/s
        	Response: 7.49 t/s
        	Total: 7.59 t/s

        Stats:
        	Prompt tokens: 21
        	Response tokens: 1264
        	Model load time: 9.10s
        	Prompt eval time: 0.62s
        	Response time: 168.76s
        	Total time: 178.48s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        deepseek-r1:latest
        	Prompt eval: 320.41 t/s
        	Response: 20.17 t/s
        	Total: 20.36 t/s

        Stats:
        	Prompt tokens: 21
        	Response tokens: 2118
        	Model load time: 4.29s
        	Prompt eval time: 0.07s
        	Response time: 105.01s
        	Total time: 109.36s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        mistral:latest
        	Prompt eval: 488.63 t/s
        	Response: 28.38 t/s
        	Total: 29.26 t/s

        Stats:
        	Prompt tokens: 25
        	Response tokens: 763
        	Model load time: 5.10s
        	Prompt eval time: 0.05s
        	Response time: 26.88s
        	Total time: 32.03s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        qwen2.5:latest
        	Prompt eval: 869.38 t/s
        	Response: 20.05 t/s
        	Total: 21.36 t/s

        Stats:
        	Prompt tokens: 73
        	Response tokens: 1086
        	Model load time: 4.82s
        	Prompt eval time: 0.08s
        	Response time: 54.18s
        	Total time: 59.09s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        gemma3:4b
        	Prompt eval: 84.96 t/s
        	Response: 27.59 t/s
        	Total: 27.93 t/s

        Stats:
        	Prompt tokens: 32
        	Response tokens: 1753
        	Model load time: 5.76s
        	Prompt eval time: 0.38s
        	Response time: 63.54s
        	Total time: 69.69s
----------------------------------------------------
