
Verbose: False
Use models: ['llama2:7b', 'llama3.1:8b', 'deepseek-r1:8b', 'deepseek-r1:latest', 'mistral:latest', 'qwen2.5:latest', 'gemma3:4b']
Skip models: []
Prompts: ['Why is the sky blue?', 'Write a report on the financials of Microsoft']

Running benchmark on all available models
Average stats:

----------------------------------------------------
        llama2:7b
        	Prompt eval: 238.14 t/s
        	Response: 26.47 t/s
        	Total: 27.59 t/s

        Stats:
        	Prompt tokens: 55
        	Response tokens: 1145
        	Model load time: 2.89s
        	Prompt eval time: 0.23s
        	Response time: 43.26s
        	Total time: 46.38s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        llama3.1:8b
        	Prompt eval: 109.36 t/s
        	Response: 18.65 t/s
        	Total: 19.11 t/s

        Stats:
        	Prompt tokens: 35
        	Response tokens: 1187
        	Model load time: 3.40s
        	Prompt eval time: 0.32s
        	Response time: 63.64s
        	Total time: 67.36s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        deepseek-r1:8b
        	Prompt eval: 191.16 t/s
        	Response: 17.61 t/s
        	Total: 17.84 t/s

        Stats:
        	Prompt tokens: 21
        	Response tokens: 1506
        	Model load time: 3.13s
        	Prompt eval time: 0.11s
        	Response time: 85.50s
        	Total time: 88.74s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        deepseek-r1:latest
        	Prompt eval: 180.05 t/s
        	Response: 18.55 t/s
        	Total: 18.69 t/s

        Stats:
        	Prompt tokens: 21
        	Response tokens: 2464
        	Model load time: 3.07s
        	Prompt eval time: 0.12s
        	Response time: 132.83s
        	Total time: 136.03s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        mistral:latest
        	Prompt eval: 378.98 t/s
        	Response: 27.61 t/s
        	Total: 28.39 t/s

        Stats:
        	Prompt tokens: 25
        	Response tokens: 814
        	Model load time: 2.58s
        	Prompt eval time: 0.07s
        	Response time: 29.49s
        	Total time: 32.13s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        qwen2.5:latest
        	Prompt eval: 414.86 t/s
        	Response: 16.52 t/s
        	Total: 17.77 t/s

        Stats:
        	Prompt tokens: 73
        	Response tokens: 922
        	Model load time: 28.70s
        	Prompt eval time: 0.18s
        	Response time: 55.81s
        	Total time: 84.69s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        gemma3:4b
        	Prompt eval: 9.47 t/s
        	Response: 20.40 t/s
        	Total: 20.02 t/s

        Stats:
        	Prompt tokens: 32
        	Response tokens: 1918
        	Model load time: 30.42s
        	Prompt eval time: 3.38s
        	Response time: 94.03s
        	Total time: 127.83s
----------------------------------------------------
