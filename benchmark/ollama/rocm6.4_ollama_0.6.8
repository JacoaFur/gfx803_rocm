Verbose: False
Use models: ['qwen2.5:latest', 'mistral:latest', 'llama3.1:8b', 'llama2:7b', 'gemma3:4b', 'deepseek-r1:latest', 'deepseek-r1:8b']
Skip models: []
Prompts: ['Why is the sky blue?', 'Write a report on the financials of Microsoft']

Running benchmark on all available models
Average stats:

----------------------------------------------------
        qwen2.5:latest
        	Prompt eval: 128.50 t/s
        	Response: 18.19 t/s
        	Total: 19.29 t/s

        Stats:
        	Prompt tokens: 73
        	Response tokens: 1026
        	Model load time: 19.41s
        	Prompt eval time: 0.57s
        	Response time: 56.41s
        	Total time: 76.40s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        mistral:latest
        	Prompt eval: 156.99 t/s
        	Response: 25.41 t/s
        	Total: 25.77 t/s

        Stats:
        	Prompt tokens: 25
        	Response tokens: 1442
        	Model load time: 5.08s
        	Prompt eval time: 0.16s
        	Response time: 56.76s
        	Total time: 62.00s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        llama3.1:8b
        	Prompt eval: 510.33 t/s
        	Response: 18.40 t/s
        	Total: 18.83 t/s

        Stats:
        	Prompt tokens: 35
        	Response tokens: 1420
        	Model load time: 5.13s
        	Prompt eval time: 0.07s
        	Response time: 77.19s
        	Total time: 82.39s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        llama2:7b
        	Prompt eval: 1104.01 t/s
        	Response: 26.52 t/s
        	Total: 27.81 t/s

        Stats:
        	Prompt tokens: 55
        	Response tokens: 1096
        	Model load time: 4.60s
        	Prompt eval time: 0.05s
        	Response time: 41.33s
        	Total time: 45.98s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        gemma3:4b
        	Prompt eval: 88.31 t/s
        	Response: 25.45 t/s
        	Total: 25.76 t/s

        Stats:
        	Prompt tokens: 32
        	Response tokens: 1852
        	Model load time: 4.88s
        	Prompt eval time: 0.36s
        	Response time: 72.77s
        	Total time: 78.01s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        deepseek-r1:latest
        	Prompt eval: 338.86 t/s
        	Response: 18.07 t/s
        	Total: 18.19 t/s

        Stats:
        	Prompt tokens: 21
        	Response tokens: 2954
        	Model load time: 22.69s
        	Prompt eval time: 0.06s
        	Response time: 163.45s
        	Total time: 186.20s
----------------------------------------------------
        
Average stats:

----------------------------------------------------
        deepseek-r1:8b
        	Prompt eval: 276.07 t/s
        	Response: 17.98 t/s
        	Total: 18.15 t/s

        Stats:
        	Prompt tokens: 21
        	Response tokens: 2145
        	Model load time: 43.31s
        	Prompt eval time: 0.08s
        	Response time: 119.28s
        	Total time: 162.67s
----------------------------------------------------
