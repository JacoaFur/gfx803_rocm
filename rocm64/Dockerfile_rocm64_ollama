# Docker Buildfile for ROCm 6.3 to use Ollama with a RX570 / Polaris / gfx803 AMD GPU
# created, build and compiled by Robert Rosenbusch at January-April 2025
# include llm-benchmnark and open-webui 

FROM rocm64_gfx803_base:latest

ENV WEBGUI_PORT=8080 \
    OLLAMA_PORT=11434 \
    OLLAMA_HOST=0.0.0.0\
    COMMANDLINE_ARGS='' 

## Checkout interactive LLM Benchmark for Ollama
RUN git clone https://github.com/willybcode/llm-benchmark.git /llm-benchmark && \
    true 

WORKDIR /llm-benchmark
RUN pip install -r requirements.txt --break-system-packages && \
    sed -i 's/return \[model\["name"\] for model in models/return \[model\["model"\] for model in models/' benchmark.py&& \ 
    sed -i 's/return OllamaResponse.model_validate(last_element)/return last_element/' benchmark.py &&\
    true

## Install Open WebUI    
WORKDIR / 
RUN curl -LsSf https://astral.sh/uv/install.sh | sh && \
    pip install open-webui --break-system-packages && \
    true
 
## Checkout Ollama
ENV OLLAMA_GIT_VERSION="v0.6.5"
RUN echo "Checkout OLLAMA: ${OLLAMA_GIT_VERSION}" && \
    git clone https://github.com/ollama/ollama.git -b ${OLLAMA_GIT_VERSION} /ollama && \
    true

## Replace gfx803 on Ollama    
WORKDIR /ollama
RUN echo "REPLACE Ollama Source for gfx803"  && \
    sed -i 's/var RocmComputeMajorMin = "9"/var RocmComputeMajorMin = "8"/' discover/gpu.go && \
    sed -i 's/"gfx900;gfx940;gfx941;gfx942;gfx1010;gfx1012;gfx1030;gfx1100;gfx1101;gfx1102;gfx906:xnack-;gfx908:xnack-;gfx90a:xnack+;gfx90a:xnack-" /"gfx803;gfx900;gfx940;gfx941;gfx942;gfx1010;gfx1012;gfx1030;gfx1100;gfx1101;gfx1102;gfx906:xnack-;gfx908:xnack-;gfx90a:xnack+;gfx90a:xnack-" /g' CMakePresets.json && \
    sed -i 's/"list(FILTER AMDGPU_TARGETS INCLUDE REGEX "^gfx(900|94[012]|101[02]|1030|110[012])$")"/"list(FILTER AMDGPU_TARGETS INCLUDE REGEX "^gfx(803|900|94[012]|101[02]|1030|110[012])$")"/g' CMakeLists.txt && \    
    sed -i 's/find_package(hip REQUIRED)/#find_package(hip REQUIRED)/' CMakeLists.txt && \
    true

## Compile Ollama    
RUN echo "BUILDING Ollama for gfx803" && \
    cmake -B build -DAMDGPU_TARGETS="${ROCM_ARCH}" && \
    cmake --build build && \    
    go generate ./... && \
    go build . && \
    true

RUN touch ol_serve.sh && \
    echo "export OLLAMA_HOST=0.0.0.0" > ol_serve.sh && \
    echo "./ollama serve&" >> ol_serve.sh && \
    chmod +x ol_serve.sh && \
    true

EXPOSE ${WEBGUI_PORT} ${OLLAMA_PORT}

#ENTRYPOINT ["export OLLAMA_HOST=0.0.0.0 ./ollama serve&"]
#CMD ["/ollama/ol_serve.sh"]

 CMD ["/bin/bash","-c"]