# Docker Buildfile for ROCm 6.4 to use Ollama with a RX570 / Polaris / gfx803 AMD GPU
# created, build and compiled by Robert Rosenbusch at January-April 2025
# include llm-benchmnark and open-webui 

#FROM rocm/dev-ubuntu-24.04:6.4-complete
FROM rocm64_gfx803_base:latest

SHELL ["/bin/bash", "-c"]  
ENV WEBGUI_PORT=8080 \
    COMMANDLINE_ARGS='' 

WORKDIR /    
###########
### Build PyTorch
###########

ENV PYTORCH_GIT_VERSION="release/2.6"
RUN echo "** Checkout PyTorch: ${PYTORCH_GIT_VERSION} **" && \  
    git clone --recursive https://github.com/ROCm/pytorch.git -b ${PYTORCH_GIT_VERSION} /pytorch && \
    true

WORKDIR /pytorch
RUN echo "** BUILDING PYTORCH *** " && \ 
    python3 --version && \
    dpkg -r --force-depends python3-yaml python3-filelock &&\
    mkdir -p /pytorch/dist && \
    python3 setup.py clean && \
    pip3 install --break-system-packages -r ${REQS_FILE} && \
    python3 tools/amd_build/build_amd.py && \
    python3 setup.py bdist_wheel && \
    pip3 install --break-system-packages dist/torch*.whl && \
    true     

###########
### Build TorchVision
###########
ENV TORCH_GIT_VERSION="release/0.21"
RUN echo "** Checkout Torchvision Version: ${TORCH_GIT_VERSION} ** " && \ 
   git clone https://github.com/pytorch/vision.git -b ${TORCH_GIT_VERSION} /vision && \
   true

WORKDIR /vision
RUN echo "** BUILDING PYTORCH *** " && \ 
    python3 setup.py bdist_wheel && \
    pip install --break-system-packages  dist/torchvision-*.whl && \
    mkdir -p /vision/dist && \
    true

###########
### Build TorchAudio
###########
ENV TORCHAUDIO_GIT_VERSION="v2.6.0"
RUN echo "** Checkout Torchaudio Version: ${TORCHAUDIO_GIT_VERSION} **" && \ 
    git clone https://github.com/pytorch/audio.git -b ${TORCHAUDIO_GIT_VERSION} /audio && \
    true

WORKDIR /audio
RUN echo "** BUILDING Torchaudio **" && \
    python3 setup.py bdist_wheel && \
    pip install --break-system-packages dist/*.whl && \
    true 


EXPOSE ${WEBGUI_PORT} ${OLLAMA_PORT}

#ENTRYPOINT ["export OLLAMA_HOST=0.0.0.0 ./ollama serve&"]
#CMD ["/ollama/ol_serve.sh"]

 CMD ["/bin/bash","-c"]