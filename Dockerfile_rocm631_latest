# Docker Buildfile for ROCm 6.2 to use ComfyUI with a RX570 / Polaris / gfx803 AMD GPU
# build and compiled by Robert Rosenbusch at August 2024

FROM rocm/pytorch:rocm6.3_ubuntu24.04_py3.12_pytorch_release_2.4.0


ENV PORT=8188 \
    COMMANDLINE_ARGS='' \
    ### how many CPUCores are using while compiling
    MAX_JOBS=14 \ 
    ### Settings for AMD GPU RX570/RX580/RX590 GPU
    HSA_OVERRIDE_GFX_VERSION=8.0.3 \ 
    AMDGPU_TARGETS=gfx803 \
    PYTORCH_ROCM_ARCH=gfx803 \
    ROCM_ARCH=gfx803 \ 
    TORCH_BLAS_PREFER_HIPBLASLT=0\ 
    ROC_ENABLE_PRE_VEGA=1 \
    USE_CUDA=0 \  
    USE_ROCM=1 \ 
    USE_NINJA=1 \
    FORCE_CUDA=1 \ 
    HSA_FORCE_FINE_GRAIN_PCIE=1 \
    #TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1 \
    #PYTORCH_TUNABLEOP_ENABLED=1 \
#######
    DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONENCODING=UTF-8\      
    REQS_FILE='requirements.txt' \
    PIP_ROOT_USER_ACTION='ignore' \
    COMMANDLINE_ARGS='' 

## Write the Environment VARSs to global... to compile later with while you use #docker save# or #docker commit#
RUN echo MAX_JOBS=${MAX_JOBS} >> /etc/environment && \ 
    echo HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION} >> /etc/environment && \ 
    echo AMDGPU_TARGETS=${AMDGPU_TARGETS} >> /etc/environment && \ 
    echo PYTORCH_ROCM_ARCH=${PYTORCH_ROCM_ARCH} >> /etc/environment && \ 
    echo ROCM_ARCH=${ROCM_ARCH} >> /etc/environment && \ 
    echo TORCH_BLAS_PREFER_HIPBLASLT=${TORCH_BLAS_PREFER_HIPBLASLT} >> /etc/environment && \ 
    echo ROC_ENABLE_PRE_VEGA=${ROC_ENABLE_PRE_VEGA} >> /etc/environment && \
    echo USE_CUDA=${USE_CUDA} >> /etc/environment && \
    echo USE_ROCM=${USE_ROCM} >> /etc/environment && \
    echo USE_NINJA=${USE_NINJA} >> /etc/environment && \
    echo FORCE_CUDA=${FORCE_CUDA} >> /etc/environment && \
    echo HSA_FORCE_FINE_GRAIN_PCIE=${HSA_FORCE_FINE_GRAIN_PCIE} >> /etc/environment && \
    #echo TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=${TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL} >> /etc/environment && \
    #echo PYTORCH_TUNABLEOP_ENABLED=${PYTORCH_TUNABLEOP_ENABLED} >> /etc/environment && \
    true

## Export the AMD Stuff
RUN export MAX_JOBS=${MAX_JOBS} && \ 
    export HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION} && \
    export ROC_ENABLE_PRE_VEGA=${ROC_ENABLE_PRE_VEGA} && \
    export AMDGPU_TARGETS=${AMDGPU_TARGETS} && \
    export PYTORCH_ROCM_ARCH=${PYTORCH_ROCM_ARCH} && \
    export ROCM_ARCH=${ROCM_ARCH} && \
    export TORCH_BLAS_PREFER_HIPBLASLT=${TORCH_BLAS_PREFER_HIPBLASLT} && \    
    export USE_CUDA=${USE_CUDA}  && \
    export USE_ROCM=${USE_ROCM}  && \
    export USE_NINJA=${USE_NINJA} && \
    export FORCE_CUDA=${FORCE_CUDA} && \
    export HSA_FORCE_FINE_GRAIN_PCIE=${HSA_FORCE_FINE_GRAIN_PCIE} && \
    #export TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=${TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL} && \
    #export  PYTORCH_TUNABLEOP_ENABLED=${PYTORCH_TUNABLEOP_ENABLED} && \
    true

# Update System and install ffmpeg for SDXL video and python virtual Env
RUN apt-get -y update && \
    apt-get install -y --no-install-recommends ffmpeg virtualenv google-perftools ccache tmux mc pigz plocate && \
    pip install --upgrade pip wheel && \
    pip install cmake mkl mkl-include && \ 
    apt --fix-broken install -y && \
    true


ENV ROCBLAS_GIT_VERSION="rocm-6.3.1"
RUN echo "Checkout ROCBLAS: ${ROCBLAS_GIT_VERSION} " && \
    git clone https://github.com/ROCm/rocBLAS.git -b ${ROCBLAS_GIT_VERSION} /rocblas && \
    true

WORKDIR /rocblas

RUN echo "BUILDING rocBLAS with ARCH: ${ROCM_ARCH} and JOBS: ${MAX_JOBS}" && \
    ./install.sh -ida ${ROCM_ARCH} -j ${MAX_JOBS} && \
    true


ENV GIT_ROCBLASLT_VERSION="rocm-6.3.1"
RUN echo "Checkout hipBLASLt: ${GIT_ROCBLASLT_VERSION} " && \
    git clone https://github.com/ROCm/hipBLASLt.git  -b ${GIT_ROCBLASLT_VERSION} /hipBLASLt && \
    true

WORKDIR /hipBLASLt

RUN echo "Install hipBLASLt " && \
    #apt --fix-broken install -y && \
    #apt install rocm-ocl-icd   -y && \
    #apt install rocm-dev -y && \
    #./install.sh -idc && \
    true


###########
# If you trust my WHL-Files i uploaded at github _and_ you are able to transfer the WHL-Files into this Docker-Image... Then comment out the following lines to the next ###########
##
# git clone PyTorch Version you need for
### PyTorch Version

ENV PYTORCH_GIT_VERSION="release/2.6"
#ENV PYTORCH_GIT_VERSION="nightly"
RUN echo "Checkout PyTorch Version: ${PYTORCH_GIT_VERSION} " && \  
    git clone --recursive https://github.com/pytorch/pytorch.git -b ${PYTORCH_GIT_VERSION} /pytorch && \
    true

#git clone Torchvision you need
## Torchvision Version
ENV TORCH_GIT_VERSION="release/0.21"
#ENV TORCH_GIT_VERSION="nightly"
RUN echo "Checkout Torchvision Version: ${TORCH_GIT_VERSION} " && \ 
   git clone https://github.com/pytorch/vision.git -b ${TORCH_GIT_VERSION} /vision && \
   true

#WORKDIR /pytorch
WORKDIR /var/lib/jenkins/pytorch
RUN echo "BULDING PYTORCH $(git describe --tags --exact | sed 's/^v//')" && \
    mkdir -p /pytorch/dist && \
    true 

RUN python setup.py clean && \
     pip install -r ${REQS_FILE} && \
     true

RUN python3 tools/amd_build/build_amd.py && \
     true

RUN echo "** BUILDING PYTORCH *** " && \ 
     python3 setup.py bdist_wheel && \
     true

RUN echo "** INSTALL PYTORCH ***" && \    
     pip install dist/torch*.whl && \
     true     

# # Build Vision
#WORKDIR /vision
WORKDIR /var/lib/jenkins/vision
#RUN export BUILD_VERSION=$(git describe --tags --exact | sed 's/^v//')  && \
RUN python3 setup.py bdist_wheel && \
    true

RUN pip install dist/*.whl && \
    mkdir -p /vision/dist && \
    true


RUN cp /var/lib/jenkins/vision/dist/*.whl /vision/dist && \
    cp /var/lib/jenkins/pytorch/dist/*.whl /pytorch/dist  && \
    true

######
# End of building pytorch and torchvision WHL-Files
###########

EXPOSE ${PORT}

CMD ["/bin/bash","-c"]

